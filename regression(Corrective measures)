#Deleting observations


#Transforming variables
#use the powerTransform() function in the car package to generate a maximum-likelihood estimation of the power λ most likely
to normalize the variable Xλ.
#The results suggest that you can normalize the variable Murder by replacing it with Murder0.6
#the hypothesis that λ=1 can’t be rejected (p = 0.145), so there’s no strong evidence that a transformation is needed in this case.
> library(car)
> summary(powerTransform(states$Murder))

#boxTidwell() function in the car package can be used to generate maximum-likelihood estimates of predictor powers that can improve linearity.
> library(car)
> boxTidwell(Murder~Population+Illiteracy,data=states)

#Adding or deleting variables

#Trying a different approach
#If there are outliers and/or influential observations, you can fit a robust regression model rather than an OLS regression. 
#If you’ve violated the normality assumption, you can fit a nonparametric regression model. 
#If there’s significant nonlinearity, you can try a nonlinear regression model. 
#If you’ve violated the assumptions of independence of errors, you can fit a model that specifically takes the error structure into account,
such as time-series models or multilevel regression models. 
#Finally, you can turn to generalized linear models to fit a wide range of models in situations where the assumptions of OLS regression don’t hold.


#Comparing models
#Because the test is nonsignificant (p = .994)，drop from the model
> states <- as.data.frame(state.x77[,c("Murder", "Population",
"Illiteracy", "Income", "Frost")])
> fit1 <- lm(Murder ~ Population + Illiteracy + Income + Frost,
data=states)
> fit2 <- lm(Murder ~ Population + Illiteracy, data=states)
> anova(fit2, fit1)

#Comparing models with the AIC
#Models with smaller AIC values—indicating adequate fit with fewer parameters—are preferred.
#Note that although the ANOVA approach requires nested models, the AIC approach doesn’t.
> fit1 <- lm(Murder ~ Population + Illiteracy + Income + Frost,
data=states)
> fit2 <- lm(Murder ~ Population + Illiteracy, data=states)
> AIC(fit1,fit2)

#Variable selection
#STEPWISE REGRESSION
#Backward stepwise selection
> library(MASS)
> states <- as.data.frame(state.x77[,c("Murder", "Population",
"Illiteracy", "Income", "Frost")])
> fit <- lm(Murder ~ Population + Illiteracy + Income + Frost,
data=states)
> stepAIC(fit, direction="backward")


#ALL SUBSETS REGRESSION
#first figure:The larger the adjusted R-square, the better
#second figure:Better models will fall close to a line with intercept 1 and slope 1
library(leaps)
states <- as.data.frame(state.x77[,c("Murder", "Population",
"Illiteracy", "Income", "Frost")])
leaps <-regsubsets(Murder ~ Population + Illiteracy + Income +
Frost, data=states, nbest=4)
plot(leaps, scale="adjr2")
library(car)
subsets(leaps, statistic="cp",
main="Cp Plot for All Subsets Regression")
abline(1,1,lty=2,col="red")


#Cross-validation
#Function for k-fold cross-validated R-square
shrinkage <- function(fit, k=10){
require(bootstrap)
theta.fit <- function(x,y){lsfit(x,y)}
theta.predict <- function(fit,x){cbind(1,x)%*%fit$coef}
x <- fit$model[,2:ncol(fit$model)]
y <- fit$model[,1]
results <- crossval(x, y, theta.fit, theta.predict, ngroup=k)
r2 <- cor(y, fit$fitted.values)^2
r2cv <- cor(y, results$cv.fit)^2
cat("Original R-square =", r2, "\n")
cat(k, "Fold Cross-Validated R-square =", r2cv, "\n")
cat("Change =", r2-r2cv, "\n")
}


#observations are assigned to the k groups randomly, so you’ll get a slightly different result each time
> states <- as.data.frame(state.x77[,c("Murder", "Population",
"Illiteracy", "Income", "Frost")])
> fit <- lm(Murder ~ Population + Income + Illiteracy + Frost, data=states)
> shrinkage(fit)

